{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25624,
     "status": "ok",
     "timestamp": 1626267309060,
     "user": {
      "displayName": "PUSHAP GANDHI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtvSq40Q0iR7PAFnCqNljCvZEL0u3Jwy5L59EZTA=s64",
      "userId": "12599792132870778014"
     },
     "user_tz": -330
    },
    "id": "caUm7WboHWvx",
    "outputId": "d7434ae8-b7a7-4795-b38b-5db9bb73e295"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3705,
     "status": "ok",
     "timestamp": 1626267312759,
     "user": {
      "displayName": "PUSHAP GANDHI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtvSq40Q0iR7PAFnCqNljCvZEL0u3Jwy5L59EZTA=s64",
      "userId": "12599792132870778014"
     },
     "user_tz": -330
    },
    "id": "bIrRb2YcEl08",
    "outputId": "f96a066a-8e09-46ed-cdbf-3bda1787af7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from  sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 912
    },
    "executionInfo": {
     "elapsed": 13979,
     "status": "ok",
     "timestamp": 1626267327924,
     "user": {
      "displayName": "PUSHAP GANDHI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtvSq40Q0iR7PAFnCqNljCvZEL0u3Jwy5L59EZTA=s64",
      "userId": "12599792132870778014"
     },
     "user_tz": -330
    },
    "id": "XHzS8qABHRKH",
    "outputId": "e1fdae23-df20-461c-e243-2f99cd122355"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>category_name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>price</th>\n",
       "      <th>shipping</th>\n",
       "      <th>item_description</th>\n",
       "      <th>log_price</th>\n",
       "      <th>name_processed</th>\n",
       "      <th>brand_name_processed</th>\n",
       "      <th>category_name_preprocessed</th>\n",
       "      <th>Tier_1</th>\n",
       "      <th>Tier_2</th>\n",
       "      <th>Tier_3</th>\n",
       "      <th>processed_item_description</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLB Cincinnati Reds T Shirt Size XL</td>\n",
       "      <td>3</td>\n",
       "      <td>Men/Tops/T-shirts</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>No description yet</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>mlb cincinnati reds shirt size xl</td>\n",
       "      <td>mlb</td>\n",
       "      <td>men/top/tshirts</td>\n",
       "      <td>men</td>\n",
       "      <td>top</td>\n",
       "      <td>tshirts</td>\n",
       "      <td>description yet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Razer BlackWidow Chroma Keyboard</td>\n",
       "      <td>3</td>\n",
       "      <td>Electronics/Computers &amp; Tablets/Components &amp; P...</td>\n",
       "      <td>Razer</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "      <td>This keyboard is in great condition and works ...</td>\n",
       "      <td>3.970292</td>\n",
       "      <td>razer blackwidow chroma keyboard</td>\n",
       "      <td>razer</td>\n",
       "      <td>electronic/computer tablet/component parts</td>\n",
       "      <td>electronic</td>\n",
       "      <td>computer tablet</td>\n",
       "      <td>component parts</td>\n",
       "      <td>keyboard great condition works like came box p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AVA-VIV Blouse</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Tops &amp; Blouses/Blouse</td>\n",
       "      <td>Target</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Adorable top with a hint of lace and a key hol...</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>avaviv blouse</td>\n",
       "      <td>target</td>\n",
       "      <td>women/top blouse/blouse</td>\n",
       "      <td>women</td>\n",
       "      <td>top blouse</td>\n",
       "      <td>blouse</td>\n",
       "      <td>adorable top hint lace key hole back pale pink...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Leather Horse Statues</td>\n",
       "      <td>1</td>\n",
       "      <td>Home/Home Décor/Home Décor Accents</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>New with tags. Leather horses. Retail for [rm]...</td>\n",
       "      <td>3.583519</td>\n",
       "      <td>leather horse statues</td>\n",
       "      <td>missing</td>\n",
       "      <td>home/home dcor/home dcor accents</td>\n",
       "      <td>home</td>\n",
       "      <td>home dcor</td>\n",
       "      <td>home dcor accents</td>\n",
       "      <td>new tags leather horses retail stand foot high...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24K GOLD plated rose</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Jewelry/Necklaces</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Complete with certificate of authenticity</td>\n",
       "      <td>3.806662</td>\n",
       "      <td>24k gold plated rose</td>\n",
       "      <td>missing</td>\n",
       "      <td>women/jewelry/necklaces</td>\n",
       "      <td>women</td>\n",
       "      <td>jewelry</td>\n",
       "      <td>necklaces</td>\n",
       "      <td>complete certificate authenticity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1482530</th>\n",
       "      <td>Free People Inspired Dress</td>\n",
       "      <td>2</td>\n",
       "      <td>Women/Dresses/Mid-Calf</td>\n",
       "      <td>Free People</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Lace, says size small but fits medium perfectl...</td>\n",
       "      <td>3.044522</td>\n",
       "      <td>free people inspired dress</td>\n",
       "      <td>free people</td>\n",
       "      <td>women/dresse/midcalf</td>\n",
       "      <td>women</td>\n",
       "      <td>dresse</td>\n",
       "      <td>midcalf</td>\n",
       "      <td>lace says size small fits medium perfectly nev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1482531</th>\n",
       "      <td>Little mermaid handmade dress</td>\n",
       "      <td>2</td>\n",
       "      <td>Kids/Girls 2T-5T/Dresses</td>\n",
       "      <td>Disney</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Little mermaid handmade dress never worn size 2t</td>\n",
       "      <td>2.708050</td>\n",
       "      <td>little mermaid handmade dress</td>\n",
       "      <td>disney</td>\n",
       "      <td>kid/girl 2t5t/dresses</td>\n",
       "      <td>kid</td>\n",
       "      <td>girl 2t5t</td>\n",
       "      <td>dresses</td>\n",
       "      <td>little mermaid handmade dress never worn size 2t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1482532</th>\n",
       "      <td>21 day fix containers and eating plan</td>\n",
       "      <td>2</td>\n",
       "      <td>Sports &amp; Outdoors/Exercise/Fitness accessories</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Used once or twice, still in great shape.</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>21 day fix containers eating plan</td>\n",
       "      <td>missing</td>\n",
       "      <td>sport outdoor/exercise/fitnes accessories</td>\n",
       "      <td>sport outdoor</td>\n",
       "      <td>exercise</td>\n",
       "      <td>fitnes accessories</td>\n",
       "      <td>used twice still great shape</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1482533</th>\n",
       "      <td>World markets lanterns</td>\n",
       "      <td>3</td>\n",
       "      <td>Home/Home Décor/Home Décor Accents</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1</td>\n",
       "      <td>There is 2 of each one that you see! So 2 red ...</td>\n",
       "      <td>3.828641</td>\n",
       "      <td>world markets lanterns</td>\n",
       "      <td>missing</td>\n",
       "      <td>home/home dcor/home dcor accents</td>\n",
       "      <td>home</td>\n",
       "      <td>home dcor</td>\n",
       "      <td>home dcor accents</td>\n",
       "      <td>2 one see 2 red 2 orange 2 big red orange ones...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1482534</th>\n",
       "      <td>Brand new lux de ville wallet</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Women's Accessories/Wallets</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>New with tag, red with sparkle. Firm price, no...</td>\n",
       "      <td>3.135494</td>\n",
       "      <td>brand new lux de ville wallet</td>\n",
       "      <td>lux</td>\n",
       "      <td>women/women accessorie/wallets</td>\n",
       "      <td>women</td>\n",
       "      <td>women accessorie</td>\n",
       "      <td>wallets</td>\n",
       "      <td>new tag red sparkle firm price free shipping</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1482535 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           name  ...                         processed_item_description\n",
       "train_id                                         ...                                                   \n",
       "0           MLB Cincinnati Reds T Shirt Size XL  ...                                    description yet\n",
       "1              Razer BlackWidow Chroma Keyboard  ...  keyboard great condition works like came box p...\n",
       "2                                AVA-VIV Blouse  ...  adorable top hint lace key hole back pale pink...\n",
       "3                         Leather Horse Statues  ...  new tags leather horses retail stand foot high...\n",
       "4                          24K GOLD plated rose  ...                  complete certificate authenticity\n",
       "...                                         ...  ...                                                ...\n",
       "1482530              Free People Inspired Dress  ...  lace says size small fits medium perfectly nev...\n",
       "1482531           Little mermaid handmade dress  ...   little mermaid handmade dress never worn size 2t\n",
       "1482532   21 day fix containers and eating plan  ...                       used twice still great shape\n",
       "1482533                  World markets lanterns  ...  2 one see 2 red 2 orange 2 big red orange ones...\n",
       "1482534           Brand new lux de ville wallet  ...       new tag red sparkle firm price free shipping\n",
       "\n",
       "[1482535 rows x 15 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LOADING THE TRAIN DATASET\n",
    "\n",
    "df= pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/cs1/actual/train_processed.csv\",index_col = [\"train_id\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 1945,
     "status": "ok",
     "timestamp": 1626267329850,
     "user": {
      "displayName": "PUSHAP GANDHI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtvSq40Q0iR7PAFnCqNljCvZEL0u3Jwy5L59EZTA=s64",
      "userId": "12599792132870778014"
     },
     "user_tz": -330
    },
    "id": "lks2xYZtvNm2"
   },
   "outputs": [],
   "source": [
    "# SPLITTING THE DATASET\n",
    "df_train,df_val = train_test_split(df,test_size=0.1,random_state = 3) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v6scN0nfyEoo"
   },
   "source": [
    "## Function1\n",
    "#### THIS FUNCTION TAKES DATAFRAME  AS INPUT AND RETURNS PREDICTION AS OUTPUT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1626267329852,
     "user": {
      "displayName": "PUSHAP GANDHI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtvSq40Q0iR7PAFnCqNljCvZEL0u3Jwy5L59EZTA=s64",
      "userId": "12599792132870778014"
     },
     "user_tz": -330
    },
    "id": "-gPJunIdF02O"
   },
   "outputs": [],
   "source": [
    "def function1(df1):\n",
    "\n",
    "    df_raw = df1 # STORING THE INPUT DATAFRAME\n",
    "\n",
    "  #ITEM CONDITON ID FEATURE\n",
    "    item_cond = df_raw.item_condition_id # STORING THE ITEM CONDITION ID\n",
    "\n",
    "  #######################################\n",
    "\n",
    "  # SHIPPING FEATURE\n",
    "    shipping = df_raw.shipping # STORING THE SHIPPING \n",
    "\n",
    "  ########################################\n",
    "\n",
    "  # NAME FEATURE\n",
    "\n",
    "  # Ref: https://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python\n",
    "    def decontracted(phrase):\n",
    "        '''THIS FUNCTION DECONTRACTS THE TEXT'''\n",
    "      # specific\n",
    "        phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
    "        phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "      # general\n",
    "        phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "        phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "        phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "        phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "        phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "        phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "        phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "        phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "        return phrase\n",
    "    \n",
    "\n",
    "    st_words = stopwords.words('english') # STORING STOPWORDS \n",
    "\n",
    "    def name_process(text):\n",
    "        '''THIS FUNCTION IS USED TO PREPROCESS THE NAME FEATURE'''\n",
    "        \n",
    "        text = decontracted(text) # DECONTRACTION\n",
    "        text = re.sub(\"[^A-Za-z0-9 ]\",\"\",text) # REMOVE EVERYTHING EXCEPT THE PROVIDED CHARACTERS\n",
    "        text = text.lower() # CONVERT TO LOWER CASE\n",
    "        text =  \" \".join([i for i in text.split() if i not in st_words])\n",
    "        if len(text)==0:\n",
    "            text = \"missing\"\n",
    "        return text # RETURN THE OUTPUT TEXT\n",
    "    \n",
    "\n",
    "    df_raw[\"name_processed\"] = df_raw.name.apply(name_process) # STORING PREPROCESSD DATA IN DATAFRAME\n",
    "    df_raw[df_raw.name_processed.isnull()].name_processed =\"missing\"  # INPUTING NULL FOR MISSING \n",
    "    \n",
    "    # TOKENIZING  \n",
    "    tk_name_processed , max_length_name_processed ,vocab_size_name_processed = pickle.load(open(\"/content/drive/MyDrive/Colab Notebooks/cs1/deep_learning_model/tk_name.h5\",\"rb\"))\n",
    "    # PADDING\n",
    "    name_pad = pad_sequences(tk_name_processed.texts_to_sequences(df_raw.name_processed),maxlen=max_length_name_processed,padding=\"post\")\n",
    "\n",
    "##########################################################################################################################\n",
    "\n",
    "  ## BRAND NAME FEATURE\n",
    "    def brand_process(text):\n",
    "        '''THIS FUNCTION PREPROCESSED THE BRAND NAME'''\n",
    "        text = re.sub(\"[^A-Za-z0-9 ]\",\"\",text)# REMOVE EVERYTHING EXCEPT THE PROVIDED CHARACTERS\n",
    "        text = text.lower()  # CONVERT TO LOWER CASE\n",
    "        return text\n",
    "    \n",
    "    '''THIS LOOP EXTRACTS BRAND NAME FROM NAME'''\n",
    "    brand_score = dict(df[df.brand_name.notnull()][\"brand_name\"].apply(brand_process).value_counts())\n",
    "\n",
    "    processed_brand_name = [] #storing the barand name after preprocessing\n",
    "    for index,i in df_raw.iterrows() : # for each row in the dataset\n",
    "      \n",
    "        if  pd.isnull(i.brand_name): #if the brand name isnull we follow this\n",
    "          \n",
    "            words = i.name_processed.split() # we will split the name for that datapoint\n",
    "            score  = [] # this variable stores the score for each word that we calculated above\n",
    "            for j in words: # for each word \n",
    "                if j in brand_score.keys(): #if the words in name is present in the keys of brand score dict\n",
    "                    score.append(brand_score[j]) # take the score from the dict and append in the score variable\n",
    "                else: #if the word is not a brand name append -1\n",
    "                    score.append(-1)\n",
    "          # once we get the scores for all the words in the name the word with maximum score woulb be the brand name\n",
    "            if max(score) > 0: #if the maximum score is greater than 0 then it contains a brand name so we append the brand name\n",
    "                processed_brand_name.append(words[score.index(max(score))])\n",
    "            else: # if maximum value is less than 0 then it means no brand name was found so \"missing\" is appended\n",
    "                processed_brand_name.append(\"missing\")\n",
    "              \n",
    "        else: # if the brand_name is not null we follow this\n",
    "            processed_brand_name.append(brand_process(i.brand_name))\n",
    "    \n",
    "    # STORES THE PROCESSED BRAND NAME IN DATAFRAME\n",
    "    df_raw[\"brand_name_processed\"] = processed_brand_name\n",
    "    \n",
    "    # TOKENIZING\n",
    "    tk_brand_name,max_length_brand_name,vocab_size_brand_name = pickle.load(open(\"/content/drive/MyDrive/Colab Notebooks/cs1/deep_learning_model/tk_brand_name.h5\",\"rb\"))\n",
    "    # PADDING\n",
    "    brand_name_pad = pad_sequences(tk_brand_name.texts_to_sequences(df_raw.brand_name_processed),maxlen=max_length_brand_name,padding=\"post\")\n",
    "\n",
    "  ########################################################################################################################################\n",
    "\n",
    "  ### CATEGORY NAME\n",
    "    def category_name_preprocessing(text):\n",
    "        ''' THIS FUNCTION PREPROCESSES THE TEXT IN \"category_name\" FEATURE'''\n",
    "        \n",
    "        text = re.sub(\"[^A-Za-z0-9/ ]\",\"\",text)# REMOVING ALL THE TEXT EXCEPT THE GIVEN CHARACTERS\n",
    "        text = re.sub(\"s \",\" \",text) # REMOVING  \"s\" AT THE END OF THE WORD\n",
    "        text = re.sub(\"s/\",\"/\",text) # REMOVING  \"s\" AT THE END OF THE WORD\n",
    "        text = re.sub(\"  \",\" \",text) # REMOVING ONE SPACE WHERE TWO SPACES ARE PRESENT\n",
    "        text = text.lower() # CONVERTING THE TEXT TO LOWER CASE\n",
    "        return text # RETURNING THE PROCESSED TEXT\n",
    "    \n",
    "    # \"missing\" TO NULL VALUES\n",
    "    df_raw.category_name[df_raw.category_name.isnull()] = \"missing\"\n",
    "    # PREPROCESS CATEGORY NAME\n",
    "    df_raw[\"category_name_preprocessed\"] = df_raw.category_name.apply(category_name_preprocessing)\n",
    "    \n",
    "    # EXTRACT TIER 1\n",
    "    df_raw[\"Tier_1\"] = df_raw.category_name_preprocessed.apply(lambda x:   x.split(\"/\")[0] if len(x.split(\"/\"))>=1 else \"missing\")\n",
    "    # TOKENIZING AND PAGGING\n",
    "    tk_tier1 , max_length_tier1 ,vocab_size_tier1 = pickle.load(open(\"/content/drive/MyDrive/Colab Notebooks/cs1/deep_learning_model/tk_tier1.h5\",\"rb\"))\n",
    "    tier1_pad = pad_sequences(tk_tier1.texts_to_sequences(df_raw.Tier_1),maxlen=max_length_tier1,padding=\"post\")\n",
    "    \n",
    "    # EXTRACI TIER 2\n",
    "    df_raw[\"Tier_2\"] = df_raw.category_name_preprocessed.apply(lambda x:   x.split(\"/\")[1] if len(x.split(\"/\"))>1 else \"missing\")\n",
    "    # TOKENIZING AND PADDING  \n",
    "    tk_tier2 , max_length_tier2 ,vocab_size_tier2 = pickle.load(open(\"/content/drive/MyDrive/Colab Notebooks/cs1/deep_learning_model/tk_tier2.h5\",\"rb\"))\n",
    "    tier2_pad = pad_sequences(tk_tier2.texts_to_sequences(df_raw.Tier_2),maxlen=max_length_tier2,padding=\"post\")\n",
    "    \n",
    "    # EXTRACT TIER3\n",
    "    df_raw[\"Tier_3\"] = df_raw.category_name_preprocessed.apply(lambda x:   x.split(\"/\")[2] if len(x.split(\"/\"))>1 else \"missing\")\n",
    "    #TOKENIZING AND PADDING\n",
    "    tk_tier3 , max_length_tier3 ,vocab_size_tier3 = pickle.load(open(\"/content/drive/MyDrive/Colab Notebooks/cs1/deep_learning_model/tk_tier3.h5\",\"rb\"))\n",
    "    tier3_pad = pad_sequences(tk_tier3.texts_to_sequences(df_raw.Tier_3),maxlen=max_length_tier3,padding=\"post\")\n",
    "  #########################################################################################################################################\n",
    "\n",
    "  # ITEM DESCRIPTION \n",
    "    \n",
    "    def processing_item_description(text):\n",
    "        '''THIS FUNCTION PREPROCESSES THE TEXT IN \"item_description\"'''\n",
    "        text = re.sub(\"\\[rm\\] \",\"\",str(text))\n",
    "        text = decontracted(text)\n",
    "        text = re.sub(\"[^A-Za-z0-9 ]\",\"\",str(text))\n",
    "        text = str(text).lower()\n",
    "        text =  \" \".join([i for i in text.split() if i not in st_words])\n",
    "        if len(text)==0:\n",
    "            text = \"missing\"\n",
    "        return text\n",
    "    # \"missing\" TO NULL VALUES\n",
    "    df_raw.item_description[df_raw.item_description.isnull()]=\"missing\"\n",
    "    df_raw[\"processed_item_description\"] = df_raw.item_description.apply(processing_item_description)\n",
    "    # TOKENIZING AND PADDING\n",
    "    tk_desc , max_len_desc ,vocab_size_desc = pickle.load(open(\"/content/drive/MyDrive/Colab Notebooks/cs1/deep_learning_model/tk_desc.h5\",\"rb\"))\n",
    "    desc_pad = pad_sequences(tk_desc.texts_to_sequences(df_raw.processed_item_description),maxlen=max_len_desc,padding=\"post\")\n",
    "    \n",
    "    # FORMING INPUT TO MODEL BY FORMING LIST OF ALL FEATURES\n",
    "    x = [item_cond,shipping,brand_name_pad,tier1_pad,tier2_pad,tier3_pad,name_pad,desc_pad]\n",
    "\n",
    "  ########################################################################################################################################\n",
    "\n",
    "  # MODEL ARCHITECTURE\n",
    "\n",
    "  # ITEM CONDITION ID\n",
    "    inp1 = layers.Input(shape=(1))\n",
    "    emb1  = layers.Embedding(6,10,input_length=1)(inp1)\n",
    "    flat1 = layers.Flatten()(emb1)\n",
    "\n",
    "  # SHIPPING \n",
    "    inp2 = layers.Input(shape=(1))\n",
    "    d2 = layers.Dense(10,activation=\"relu\")(inp2)\n",
    "\n",
    "  # BRAND NAME\n",
    "    inp3 = layers.Input(shape= (8))\n",
    "    emb3 = layers.Embedding(vocab_size_brand_name ,16 ,input_length= 8 )(inp3)\n",
    "    flat3 = layers.Flatten()(emb3)\n",
    "\n",
    "  # Tier_1\n",
    "    inp4 = layers.Input(shape = (2))\n",
    "    emb4 = layers.Embedding(vocab_size_tier1, 16 , input_length=2 )(inp4)\n",
    "    flat4 = layers.Flatten()(emb4)\n",
    "\n",
    "  # Tier_2\n",
    "    inp5= layers.Input(shape = (4))\n",
    "    emb5 = layers.Embedding(vocab_size_tier2 , 16 ,input_length= 4 )(inp5)\n",
    "    flat5 = layers.Flatten()(emb5)\n",
    "\n",
    "  # Tier_3\n",
    "    inp6= layers.Input(shape = (6))\n",
    "    emb6 = layers.Embedding(vocab_size_tier3, 16 ,input_length= 6 )(inp6)\n",
    "    flat6 = layers.Flatten()(emb6)\n",
    "\n",
    "  # NAME PROCESSED\n",
    "    inp7= layers.Input(shape = (13))\n",
    "    emb7 = layers.Embedding(vocab_size_name_processed,20 ,input_length= 13 )(inp7)\n",
    "    lstm7 = layers.GRU(64,return_sequences=True)(emb7)\n",
    "    flat7 = layers.Flatten()(lstm7)\n",
    "\n",
    "  # ITEM DESCRIPTION\n",
    "    inp8= layers.Input(shape = (193))\n",
    "    emb8 = layers.Embedding(vocab_size_desc , 40 , input_length= 193 )(inp8)\n",
    "    lstm8 = layers.GRU(64,return_sequences=True)(emb8)\n",
    "    flat8 = layers.Flatten()(lstm8)\n",
    "\n",
    "    concat = layers.Concatenate()([flat1,d2,flat3,flat4,flat5,flat6,flat7,flat8])\n",
    "\n",
    "    dense1 = layers.Dense(512,activation=\"relu\")(concat)\n",
    "    drop2 = layers.Dropout(0.2)(dense1)\n",
    "\n",
    "    dense2 = layers.Dense(256,activation=\"relu\")(drop2)\n",
    "    drop2 = layers.Dropout(0.3)(dense2)\n",
    "\n",
    "\n",
    "    dense3 = layers.Dense(128,activation=\"relu\")(drop2)\n",
    "    drop2 = layers.Dropout(0.4)(dense3)\n",
    "    bn2  = layers.BatchNormalization()(drop2)\n",
    "\n",
    "    dense4 = layers.Dense(1,activation=\"linear\")(bn2)\n",
    "\n",
    "    model =  Model(inputs= [inp1,inp2,inp3,inp4,inp5,inp6,inp7,inp8],outputs=dense4)\n",
    "    # COMPILING MODEL\n",
    "    model.compile(optimizer=\"adam\",loss=\"mse\",metrics=  tf.keras.metrics.RootMeanSquaredError())\n",
    "    # LOADING THE WEIGHTS\n",
    "    model.load_weights(\"/content/drive/MyDrive/Colab Notebooks/cs1/deep_learning_model/save1/best.h5\")\n",
    "    \n",
    "    # PREDICT THE OUTPUT\n",
    "    x_pred = model.predict(x,batch_size=100)\n",
    "    \n",
    "    # LOG PRICE TO ACTUAL VALUES\n",
    "    def log_to_actual(log):\n",
    "        return np.exp(log)-1\n",
    "    \n",
    "    # FORING DATAFRAME OF RESULTS\n",
    "    x_pred_df = pd.DataFrame(log_to_actual(x_pred),columns=[\"price\"])\n",
    "\n",
    "    return x_pred_df # RETURN PREDICTIONS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "executionInfo": {
     "elapsed": 23866,
     "status": "ok",
     "timestamp": 1626267603509,
     "user": {
      "displayName": "PUSHAP GANDHI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtvSq40Q0iR7PAFnCqNljCvZEL0u3Jwy5L59EZTA=s64",
      "userId": "12599792132870778014"
     },
     "user_tz": -330
    },
    "id": "LeX7cEZQFhWM",
    "outputId": "1b4d604b-fc9b-4f74-f113-eb12017c5481"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.846291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>87.511360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.222604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25.103687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26.167284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>70.665016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>57.194221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>17.034887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>13.999576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>17.339582</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       price\n",
       "0   8.846291\n",
       "1  87.511360\n",
       "2  10.222604\n",
       "3  25.103687\n",
       "4  26.167284\n",
       "5  70.665016\n",
       "6  57.194221\n",
       "7  17.034887\n",
       "8  13.999576\n",
       "9  17.339582"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RESULTS OF  FIRST 10 ROWS OF DATAFRAME\n",
    "function1(df[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 114
    },
    "executionInfo": {
     "elapsed": 4896,
     "status": "ok",
     "timestamp": 1626178658134,
     "user": {
      "displayName": "PUSHAP GANDHI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtvSq40Q0iR7PAFnCqNljCvZEL0u3Jwy5L59EZTA=s64",
      "userId": "12599792132870778014"
     },
     "user_tz": -330
    },
    "id": "IwMljZV2F0zi",
    "outputId": "a98e0df7-4c83-49d5-aac1-21f55761cfca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.97 s, sys: 147 ms, total: 4.12 s\n",
      "Wall time: 4.08 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.806379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      price\n",
       "0  8.806379"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PREDICTION OF ONE DATAPOINT\n",
    "%%time\n",
    "function1(df_val[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bXwv-H-PxqJE"
   },
   "source": [
    "* The model takes 4 seconds for one prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "executionInfo": {
     "elapsed": 61793,
     "status": "ok",
     "timestamp": 1626178454453,
     "user": {
      "displayName": "PUSHAP GANDHI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtvSq40Q0iR7PAFnCqNljCvZEL0u3Jwy5L59EZTA=s64",
      "userId": "12599792132870778014"
     },
     "user_tz": -330
    },
    "id": "-1A8O5NAx-1Q",
    "outputId": "5fd6724f-b341-4fa5-b37e-7a1404d04742"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.806379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.665524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23.337391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.904898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.096342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148249</th>\n",
       "      <td>11.028755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148250</th>\n",
       "      <td>12.779449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148251</th>\n",
       "      <td>11.481474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148252</th>\n",
       "      <td>20.258106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148253</th>\n",
       "      <td>10.608234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>148254 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            price\n",
       "0        8.806379\n",
       "1       13.665524\n",
       "2       23.337391\n",
       "3       18.904898\n",
       "4       16.096342\n",
       "...           ...\n",
       "148249  11.028755\n",
       "148250  12.779449\n",
       "148251  11.481474\n",
       "148252  20.258106\n",
       "148253  10.608234\n",
       "\n",
       "[148254 rows x 1 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PREDICTION OF VALIDATION DATA\n",
    "function1(df_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M5jhoikpx_uo"
   },
   "source": [
    "## Function2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### THIS FUNCTION TAKES DATAFRAME AS INPUT AND RETURNS METRIC RMSLE AS OUTPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nZEuiMSsj-r3"
   },
   "outputs": [],
   "source": [
    "def function2(df1,y_price):\n",
    "\n",
    "    df_raw = df1\n",
    "\n",
    "  #ITEM CONDITON ID FEATURE\n",
    "    item_cond = df_raw.item_condition_id\n",
    "\n",
    "  ################################################.\n",
    "\n",
    "  # SHIPPING FEATURE\n",
    "    shipping = df_raw.shipping\n",
    "\n",
    "  #######################################################\n",
    "\n",
    "  # NAME FEATURE\n",
    "\n",
    "  # Ref: https://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python\n",
    "    def decontracted(phrase):\n",
    "      # specific\n",
    "        phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
    "        phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "        # general\n",
    "        phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "        phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "        phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "        phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "        phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "        phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "        phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "        phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "        return phrase\n",
    "\n",
    "    st_words = stopwords.words('english')\n",
    "\n",
    "    def name_process(text):\n",
    "        '''THIS FUNCTION IS USED TO PREPROCESS THE NAME FEATURE'''\n",
    "        text = decontracted(text)\n",
    "        text = re.sub(\"[^A-Za-z0-9 ]\",\"\",text) # REMOVE EVERYTHING EXCEPT THE PROVIDED CHARACTERS\n",
    "        text = text.lower() # CONVERT TO LOWER CASE\n",
    "        text =  \" \".join([i for i in text.split() if i not in st_words])\n",
    "        if len(text)==0:\n",
    "            text = \"missing\"\n",
    "        return text # RETURN THE OUTPUT TEXT\n",
    "\n",
    "    df_raw[\"name_processed\"] = df_raw.name.apply(name_process)\n",
    "    df_raw[df_raw.name_processed.isnull()].name_processed =\"missing\" \n",
    "\n",
    "    tk_name_processed , max_length_name_processed ,vocab_size_name_processed = pickle.load(open(\"/content/drive/MyDrive/Colab Notebooks/cs1/deep_learning_model/tk_name.h5\",\"rb\"))\n",
    "    name_pad = pad_sequences(tk_name_processed.texts_to_sequences(df_raw.name_processed),maxlen=max_length_name_processed,padding=\"post\")\n",
    "\n",
    "  ############################################################################################################################################\n",
    "\n",
    "  ## BRAND NAME FEATURE\n",
    "    def brand_process(text):\n",
    "        text = re.sub(\"[^A-Za-z0-9 ]\",\"\",text)# REMOVE EVERYTHING EXCEPT THE PROVIDED CHARACTERS\n",
    "        text = text.lower()  # CONVERT TO LOWER CASE\n",
    "        return text\n",
    "\n",
    "\n",
    "    brand_score = dict(df[df.brand_name.notnull()][\"brand_name\"].apply(brand_process).value_counts())\n",
    "\n",
    "    processed_brand_name = [] #storing the barand name after preprocessing\n",
    "    for index,i in df_raw.iterrows() : # for each row in the dataset\n",
    "      \n",
    "        if  pd.isnull(i.brand_name): #if the brand name isnull we follow this\n",
    "          \n",
    "        words = i.name_processed.split() # we will split the name for that datapoint\n",
    "        score  = [] # this variable stores the score for each word that we calculated above\n",
    "        for j in words: # for each word \n",
    "            if j in brand_score.keys(): #if the words in name is present in the keys of brand score dict\n",
    "                score.append(brand_score[j]) # take the score from the dict and append in the score variable\n",
    "            else: #if the word is not a brand name append -1\n",
    "                score.append(-1)\n",
    "          # once we get the scores for all the words in the name the word with maximum score woulb be the brand name\n",
    "            if max(score) > 0: #if the maximum score is greater than 0 then it contains a brand name so we append the brand name\n",
    "                processed_brand_name.append(words[score.index(max(score))])\n",
    "            else: # if maximum value is less than 0 then it means no brand name was found so \"missing\" is appended\n",
    "                processed_brand_name.append(\"missing\")\n",
    "              \n",
    "        else: # if the brand_name is not null we follow this\n",
    "            processed_brand_name.append(brand_process(i.brand_name))\n",
    "\n",
    "    df_raw[\"brand_name_processed\"] = processed_brand_name\n",
    "\n",
    "    tk_brand_name,max_length_brand_name,vocab_size_brand_name = pickle.load(open(\"/content/drive/MyDrive/Colab Notebooks/cs1/deep_learning_model/tk_brand_name.h5\",\"rb\"))\n",
    "    brand_name_pad = pad_sequences(tk_brand_name.texts_to_sequences(df_raw.brand_name_processed),maxlen=max_length_brand_name,padding=\"post\")\n",
    "\n",
    "  #############################################################################################################################################\n",
    "\n",
    "  ### CATEGORY NAME\n",
    "\n",
    "    def category_name_preprocessing(text):\n",
    "        ''' THIS FUNCTION PREPROCESSES THE TEXT IN \"category_name\" FEATURE'''\n",
    "        text = re.sub(\"[^A-Za-z0-9/ ]\",\"\",text)# REMOVING ALL THE TEXT EXCEPT THE GIVEN CHARACTERS\n",
    "        text = re.sub(\"s \",\" \",text) # REMOVING  \"s\" AT THE END OF THE WORD\n",
    "        text = re.sub(\"s/\",\"/\",text) # REMOVING  \"s\" AT THE END OF THE WORD\n",
    "        text = re.sub(\"  \",\" \",text) # REMOVING ONE SPACE WHERE TWO SPACES ARE PRESENT\n",
    "        text = text.lower() # CONVERTING THE TEXT TO LOWER CASE\n",
    "        return text # RETURNING THE PROCESSED TEXT\n",
    "    \n",
    "    df_raw.category_name[df_raw.category_name.isnull()] = \"missing\"\n",
    "    df_raw[\"category_name_preprocessed\"] = df_raw.category_name.apply(category_name_preprocessing)\n",
    "\n",
    "    df_raw[\"Tier_1\"] = df_raw.category_name_preprocessed.apply(lambda x:   x.split(\"/\")[0] if len(x.split(\"/\"))>=1 else \"missing\")\n",
    "\n",
    "    tk_tier1 , max_length_tier1 ,vocab_size_tier1 = pickle.load(open(\"/content/drive/MyDrive/Colab Notebooks/cs1/deep_learning_model/tk_tier1.h5\",\"rb\"))\n",
    "    tier1_pad = pad_sequences(tk_tier1.texts_to_sequences(df_raw.Tier_1),maxlen=max_length_tier1,padding=\"post\")\n",
    "\n",
    "\n",
    "    df_raw[\"Tier_2\"] = df_raw.category_name_preprocessed.apply(lambda x:   x.split(\"/\")[1] if len(x.split(\"/\"))>1 else \"missing\")\n",
    "\n",
    "    tk_tier2 , max_length_tier2 ,vocab_size_tier2 = pickle.load(open(\"/content/drive/MyDrive/Colab Notebooks/cs1/deep_learning_model/tk_tier2.h5\",\"rb\"))\n",
    "    tier2_pad = pad_sequences(tk_tier2.texts_to_sequences(df_raw.Tier_2),maxlen=max_length_tier2,padding=\"post\")\n",
    "\n",
    "    df_raw[\"Tier_3\"] = df_raw.category_name_preprocessed.apply(lambda x:   x.split(\"/\")[2] if len(x.split(\"/\"))>1 else \"missing\")\n",
    "\n",
    "    tk_tier3 , max_length_tier3 ,vocab_size_tier3 = pickle.load(open(\"/content/drive/MyDrive/Colab Notebooks/cs1/deep_learning_model/tk_tier3.h5\",\"rb\"))\n",
    "    tier3_pad = pad_sequences(tk_tier3.texts_to_sequences(df_raw.Tier_3),maxlen=max_length_tier3,padding=\"post\")\n",
    "\n",
    "  ##################################################################################################################################\n",
    "\n",
    "  # ITEM DESCRIPTION \n",
    "    \n",
    "    def processing_item_description(text):\n",
    "        '''THIS FUNCTION PREPROCESSES THE TEXT IN \"item_description\"'''\n",
    "        text = re.sub(\"\\[rm\\] \",\"\",str(text))\n",
    "        text = decontracted(text)\n",
    "        text = re.sub(\"[^A-Za-z0-9 ]\",\"\",str(text))\n",
    "        text = str(text).lower()\n",
    "        text =  \" \".join([i for i in text.split() if i not in st_words])\n",
    "        if len(text)==0:\n",
    "            text = \"missing\"\n",
    "        return text\n",
    "\n",
    "    df_raw.item_description[df_raw.item_description.isnull()]=\"missing\"\n",
    "    df_raw[\"processed_item_description\"] = df_raw.item_description.apply(processing_item_description)\n",
    "\n",
    "    tk_desc , max_len_desc ,vocab_size_desc = pickle.load(open(\"/content/drive/MyDrive/Colab Notebooks/cs1/deep_learning_model/tk_desc.h5\",\"rb\"))\n",
    "    desc_pad = pad_sequences(tk_desc.texts_to_sequences(df_raw.processed_item_description),maxlen=max_len_desc,padding=\"post\")\n",
    "\n",
    "    x = [item_cond,shipping,brand_name_pad,tier1_pad,tier2_pad,tier3_pad,name_pad,desc_pad]\n",
    "\n",
    "  ##################################################################################################################################\n",
    "\n",
    "  # ITEM CONDITION ID\n",
    "    inp1 = layers.Input(shape=(1))\n",
    "    emb1  = layers.Embedding(6,10,input_length=1)(inp1)\n",
    "    flat1 = layers.Flatten()(emb1)\n",
    "\n",
    "\n",
    "  # SHIPPING \n",
    "    inp2 = layers.Input(shape=(1))\n",
    "    d2 = layers.Dense(10,activation=\"relu\")(inp2)\n",
    "\n",
    "\n",
    "    # BRAND NAME\n",
    "    inp3 = layers.Input(shape= (8))\n",
    "    emb3 = layers.Embedding(vocab_size_brand_name ,16 ,input_length= 8 )(inp3)\n",
    "    flat3 = layers.Flatten()(emb3)\n",
    "\n",
    "    # Tier_1\n",
    "    inp4 = layers.Input(shape = (2))\n",
    "    emb4 = layers.Embedding(vocab_size_tier1, 16 , input_length=2 )(inp4)\n",
    "    flat4 = layers.Flatten()(emb4)\n",
    "\n",
    "    # Tier_2\n",
    "    inp5= layers.Input(shape = (4))\n",
    "    emb5 = layers.Embedding(vocab_size_tier2 , 16 ,input_length= 4 )(inp5)\n",
    "    flat5 = layers.Flatten()(emb5)\n",
    "\n",
    "    # Tier_3\n",
    "    inp6= layers.Input(shape = (6))\n",
    "    emb6 = layers.Embedding(vocab_size_tier3, 16 ,input_length= 6 )(inp6)\n",
    "    flat6 = layers.Flatten()(emb6)\n",
    "\n",
    "    # NAME PROCESSED\n",
    "    inp7= layers.Input(shape = (13))\n",
    "    emb7 = layers.Embedding(vocab_size_name_processed,20 ,input_length= 13 )(inp7)\n",
    "    lstm7 = layers.GRU(64,return_sequences=True)(emb7)\n",
    "    flat7 = layers.Flatten()(lstm7)\n",
    "\n",
    "    # ITEM DESCRIPTION\n",
    "    inp8= layers.Input(shape = (193))\n",
    "    emb8 = layers.Embedding(vocab_size_desc , 40 , input_length= 193 )(inp8)\n",
    "    lstm8 = layers.GRU(64,return_sequences=True)(emb8)\n",
    "    flat8 = layers.Flatten()(lstm8)\n",
    "\n",
    "    concat = layers.Concatenate()([flat1,d2,flat3,flat4,flat5,flat6,flat7,flat8])\n",
    "\n",
    "    dense1 = layers.Dense(512,activation=\"relu\")(concat)\n",
    "    drop2 = layers.Dropout(0.2)(dense1)\n",
    "\n",
    "    dense2 = layers.Dense(256,activation=\"relu\")(drop2)\n",
    "    drop2 = layers.Dropout(0.3)(dense2)\n",
    "\n",
    "\n",
    "    dense3 = layers.Dense(128,activation=\"relu\")(drop2)\n",
    "    drop2 = layers.Dropout(0.4)(dense3)\n",
    "    bn2  = layers.BatchNormalization()(drop2)\n",
    "\n",
    "    dense4 = layers.Dense(1,activation=\"linear\")(bn2)\n",
    "    # MODEL\n",
    "    model =  Model(inputs= [inp1,inp2,inp3,inp4,inp5,inp6,inp7,inp8],outputs=dense4)\n",
    "    model.compile(optimizer=\"adam\",loss=\"mse\",metrics=  tf.keras.metrics.RootMeanSquaredError())\n",
    "    #LOAD WEIGHTS\n",
    "    model.load_weights(\"/content/drive/MyDrive/Colab Notebooks/cs1/deep_learning_model/save1/best.h5\")\n",
    "    \n",
    "    # EVALUATE THE RMSLE VALUES\n",
    "    rmse = model.evaluate(x,np.log(y_price+1),verbose=1,batch_size=1000)\n",
    "  \n",
    "    return rmse[1] # RETURN RMSLE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 90063,
     "status": "ok",
     "timestamp": 1626177475218,
     "user": {
      "displayName": "PUSHAP GANDHI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtvSq40Q0iR7PAFnCqNljCvZEL0u3Jwy5L59EZTA=s64",
      "userId": "12599792132870778014"
     },
     "user_tz": -330
    },
    "id": "LE4-jC27uPru",
    "outputId": "88d9d637-a6bc-423d-9223-6373fca6e6b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4633/4633 [==============================] - 40s 9ms/step - loss: 0.1864 - root_mean_squared_error: 0.4318\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.43175092339515686"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EVALUATION OF METRIC FOR VALIDATION DATA\n",
    "function2(df_val,df_val.price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jwoCD2u2vbgK"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMS0I2J9W/ZITzRvc/NrJDZ",
   "collapsed_sections": [],
   "name": "Final_CS1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
